{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as BS\n",
    "\n",
    "import pandas as pd\n",
    "#import bs4\n",
    "#pip install --upgrade html5lib==1.0b8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start with a Simple Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./index.html')\n",
    "html = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      "<head>\n",
      "<title>My Page</title>\n",
      "</head>\n",
      "<body bgcolor=\"yellow\">\n",
      "<h1>Welcome to my page!</h1>\n",
      "<br/><hr/>\n",
      "<p>Lorem Ipsum Lorem Ipsum Lorem Ipsum Lorem Ipsum</p>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "soup = BS(html)\n",
    "print soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>My Page</title>\n",
      "My Page\n"
     ]
    }
   ],
   "source": [
    "print soup.html.head.title\n",
    "print soup.html.head.title.text\n",
    "#soup.html.head.title.text       if we doesnot useprint statement then text wil come in unicode format\n",
    "#Hota hi unicde form me hai text vgara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Page\n",
      "Welcome to my page!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# if we know the html structure then we do this for small html file\n",
    "# print soup.html.head.title.text\n",
    "# print soup.html.body.h1.text\n",
    "\n",
    "# if th depth of a tree is about 100 or more then it the in such cases we use soup.find_all\n",
    "\n",
    "#print soup.find_all('title')           # This will come in a list format\n",
    "#print soup.find_all('div')           # This will come in a list format  div tag not exists but it gib=ve an empty list\n",
    "\n",
    "print soup.find_all('title')[0].text #Thats why we use listing we use 0 in this case because we have only one title if a html page have multiple titles then we use any other no as well to acces that particular title\n",
    "print soup.find_all('h1')[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape XKCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "url = 'https://xkcd.com/1853/'\n",
    "#Is particular Url pr ab hum get request bhejne vale hai\n",
    "r = requests.get(url)\n",
    "#requests.   #refer to documnetation\n",
    "print r.status_code   #It means success basciallly now in r there will be a html code for this url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print r.text         #An Html document file for this url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BS(r.text)      #Now pass it to beautifulsoup for getting an internal tree of this html file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://imgs.xkcd.com/comics/once_per_day.png\n"
     ]
    }
   ],
   "source": [
    "# Get all the div elements\n",
    "\n",
    "#divs= soup.find_all('div')\n",
    "#print len(divs)                # 17 divs we how recognize our div so give id\n",
    "#print divs[4]\n",
    "divs = soup.find_all('div', id='comic')\n",
    "#print len(divs)       #Our current vala div\n",
    "#print divs[0]         #Div visual\n",
    "\n",
    "image_div =  divs[0]\n",
    "#print image_div.img['src']     #//imgs.xkcd.com/comics/refresh_types.png this // means a realative path if we paste this url afer server name then it runs   \n",
    "#for perfect url\n",
    "image_url = 'https:' + image_div.img['src']\n",
    "print image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapping this all in a function\n",
    "def get_xkcd_image(idx=1000):\n",
    "    url = 'https://xkcd.com/{}/'.format(idx)\n",
    "    img_url = None\n",
    "    r = requests.get(url)\n",
    "    if r.status_code == 200:\n",
    "        soup = BS(r.text)\n",
    "        img_url = 'https:' + soup.find_all('div', id='comic')[0].img['src']    # same code jo hmne upr kia h bus ye ek line me likh dia\n",
    "    return img_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 https://imgs.xkcd.com/comics/barrel_cropped_(1).jpg\n",
      "101 https://imgs.xkcd.com/comics/laser_scope.jpg\n",
      "201 https://imgs.xkcd.com/comics/christmas_gps.png\n",
      "301 https://imgs.xkcd.com/comics/limerick.png\n",
      "401 https://imgs.xkcd.com/comics/large_hadron_collider.png\n",
      "501 https://imgs.xkcd.com/comics/faust_20.png\n",
      "601 https://imgs.xkcd.com/comics/game_theory.png\n",
      "701 https://imgs.xkcd.com/comics/science_valentine.png\n",
      "801 https://imgs.xkcd.com/comics/golden_hammer.png\n",
      "901 https://imgs.xkcd.com/comics/temperature.png\n"
     ]
    }
   ],
   "source": [
    "for ix in range(1, 1000, 100):  #last 100 is used for skip\n",
    "    print ix, get_xkcd_image(ix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Datatau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "url = 'http://www.datatau.com/'\n",
    "\n",
    "r = requests.get(url)\n",
    "print r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BS(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n"
     ]
    }
   ],
   "source": [
    "main_table = soup.find_all('table')[2]\n",
    "\n",
    "#print main_table\n",
    "rows = main_table.find_all('tr')\n",
    "print len(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Scikit-learn pipeline in Wallaroo\n"
     ]
    }
   ],
   "source": [
    "# lop kihne se phle maine test kia h ek row pe\n",
    "\n",
    "#td_elem = rows[0].find_all('td')[-1]      ## This we want to take out of one row the third td(that is also the last td in a row tag) because first and second doesnot a\n",
    "#print td_elem       #phli row ka last td\n",
    "#print td_elem.a['href']      #a is tag and href is our attribute so we given href in list format\n",
    "#print td_elem.a.text        #output ----A Scikit-learn pipeline in Wallaroo\n",
    "# int(rows[1].find_all('span')[0].text.split()[0])\n",
    "\n",
    "all_data = pd.DataFrame([], columns=['title', 'url', 'points'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-89-f78641b238dd>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-89-f78641b238dd>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    }\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# har 3 row ke liye print kraunga\n",
    "for ix in range(0, 90, 3):\n",
    "    td_elem = rows[ix].find_all('td')[-1]  # This we want to take out of one row the third td(that is also the last td in a row tag) because first and second doesnot a class objects hence no use\n",
    "    #print td_elem\n",
    "    #  And [-1] is given to acces the last td of a row\n",
    "    #print len(td_elem)  #all last td of 30 rows   #length of td_elem is 2\n",
    "    # Make a dictionary to access the attributes of a td tag \n",
    "    \n",
    "    data = {\n",
    "        'title': td_elem.a.text,    # Anchor tag ka text title me dlwa lia\n",
    "        'url': td_elem.a['href'],   # This is url\n",
    "        'points': int(rows[ix+1].find_all('span')[0].text.split()[0])\n",
    "    }\n",
    "    \n",
    "    all_data = all_data.append(data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Scikit-learn pipeline in Wallaroo</td>\n",
       "      <td>https://blog.wallaroolabs.com/2018/02/a-scikit...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Practical Apache Spark in 10 minutes. Part 4 —...</td>\n",
       "      <td>https://medium.com/data-science-school/practic...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The most in-demand tech roles and industries f...</td>\n",
       "      <td>https://statsbot.co/blog/best-tech-roles-and-i...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Using GPUs to Analyze Mice in Space</td>\n",
       "      <td>https://www.mapd.com/blog/analyzing-nasa-space...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Multi data and outputs volumes for you DL and ...</td>\n",
       "      <td>https://medium.com/polyaxon/mounting-multiple-...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                A Scikit-learn pipeline in Wallaroo   \n",
       "1  Practical Apache Spark in 10 minutes. Part 4 —...   \n",
       "2  The most in-demand tech roles and industries f...   \n",
       "3                Using GPUs to Analyze Mice in Space   \n",
       "4  Multi data and outputs volumes for you DL and ...   \n",
       "\n",
       "                                                 url points  \n",
       "0  https://blog.wallaroolabs.com/2018/02/a-scikit...      2  \n",
       "1  https://medium.com/data-science-school/practic...     18  \n",
       "2  https://statsbot.co/blog/best-tech-roles-and-i...      6  \n",
       "3  https://www.mapd.com/blog/analyzing-nasa-space...      4  \n",
       "4  https://medium.com/polyaxon/mounting-multiple-...      4  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For self practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tr><td align=\"right\" class=\"title\" valign=\"top\">1.</td><td><center><a href=\"vote?for=25617&amp;dir=up&amp;whence=%6e%65%77%73\" id=\"nil\"><img border=\"0\" hspace=\"2\" src=\"grayarrow.gif\" vspace=\"3\"/></a><span id=\"down_25617\"></span></center></td><td class=\"title\"><a href=\"https://blog.wallaroolabs.com/2018/02/a-scikit-learn-pipeline-in-wallaroo/\" rel=\"nofollow\">A Scikit-learn pipeline in Wallaroo</a><span class=\"comhead\"> (wallaroolabs.com) </span></td></tr>\n",
      "<tr><td align=\"right\" class=\"title\" valign=\"top\">2.</td><td><center><a href=\"vote?for=25500&amp;dir=up&amp;whence=%6e%65%77%73\" id=\"nil\"><img border=\"0\" hspace=\"2\" src=\"grayarrow.gif\" vspace=\"3\"/></a><span id=\"down_25500\"></span></center></td><td class=\"title\"><a href=\"https://medium.com/data-science-school/practical-apache-spark-in-10-minutes-part-4-mllib-fca02fecf5b8\">Practical Apache Spark in 10 minutes. Part 4 — MLlib</a><span class=\"comhead\"> (medium.com) </span></td></tr>\n",
      "<tr><td align=\"right\" class=\"title\" valign=\"top\">3.</td><td><center><a href=\"vote?for=25544&amp;dir=up&amp;whence=%6e%65%77%73\" id=\"nil\"><img border=\"0\" hspace=\"2\" src=\"grayarrow.gif\" vspace=\"3\"/></a><span id=\"down_25544\"></span></center></td><td class=\"title\"><a href=\"https://statsbot.co/blog/best-tech-roles-and-industries-in-2018\">The most in-demand tech roles and industries for 2018 [Data Visualized]</a><span class=\"comhead\"> (statsbot.co) </span></td></tr>\n",
      "<tr><td align=\"right\" class=\"title\" valign=\"top\">4.</td><td><center><a href=\"vote?for=25510&amp;dir=up&amp;whence=%6e%65%77%73\" id=\"nil\"><img border=\"0\" hspace=\"2\" src=\"grayarrow.gif\" vspace=\"3\"/></a><span id=\"down_25510\"></span></center></td><td class=\"title\"><a href=\"https://www.mapd.com/blog/analyzing-nasa-spaceflight-microgravity-effects-on-mice-repertoire/\" rel=\"nofollow\">Using GPUs to Analyze Mice in Space</a><span class=\"comhead\"> (mapd.com) </span></td></tr>\n",
      "<tr><td align=\"right\" class=\"title\" valign=\"top\">5.</td><td><center><a href=\"vote?for=25497&amp;dir=up&amp;whence=%6e%65%77%73\" id=\"nil\"><img border=\"0\" hspace=\"2\" src=\"grayarrow.gif\" vspace=\"3\"/></a><span id=\"down_25497\"></span></center></td><td class=\"title\"><a href=\"https://medium.com/polyaxon/mounting-multiple-data-and-outputs-volumes-41f2d912f2f8\" rel=\"nofollow\">Multi data and outputs volumes for you DL and ML experiments with Polyaxon</a><span class=\"comhead\"> (medium.com) </span></td></tr>\n",
      "<tr><td align=\"right\" class=\"title\" valign=\"top\">6.</td><td><center><a href=\"vote?for=25301&amp;dir=up&amp;whence=%6e%65%77%73\" id=\"nil\"><img border=\"0\" hspace=\"2\" src=\"grayarrow.gif\" vspace=\"3\"/></a><span id=\"down_25301\"></span></center></td><td class=\"title\"><a href=\"https://medium.com/activewizards-machine-learning-company/top-10-data-science-use-cases-in-insurance-8cade8a13ee1\">Top 10 Data Science Use Cases in Insurance</a><span class=\"comhead\"> (medium.com) </span></td></tr>\n",
      "<tr><td align=\"right\" class=\"title\" valign=\"top\">7.</td><td><center><a href=\"vote?for=25519&amp;dir=up&amp;whence=%6e%65%77%73\" id=\"nil\"><img border=\"0\" hspace=\"2\" src=\"grayarrow.gif\" vspace=\"3\"/></a><span id=\"down_25519\"></span></center></td><td class=\"title\"><a href=\"https://www.interviewqs.com/blog/pythonsheets\" rel=\"nofollow\">Reading and writing to Google Spreadsheets using Python</a><span class=\"comhead\"> (interviewqs.com) </span></td></tr>\n",
      "<tr><td align=\"right\" class=\"title\" valign=\"top\">8.</td><td><center><a href=\"vote?for=25554&amp;dir=up&amp;whence=%6e%65%77%73\" id=\"nil\"><img border=\"0\" hspace=\"2\" src=\"grayarrow.gif\" vspace=\"3\"/></a><span id=\"down_25554\"></span></center></td><td class=\"title\"><a href=\"https://data36.com/pandas-tutorial-1-basics-reading-data-files-dataframes-data-selection/\" rel=\"nofollow\">Pandas Tutorial 1: Basics (Reading Data Files, DataFrames, Data Selection)</a><span class=\"comhead\"> (data36.com) </span></td></tr>\n",
      "<tr><td align=\"right\" class=\"title\" valign=\"top\">9.</td><td><center><a href=\"vote?for=25496&amp;dir=up&amp;whence=%6e%65%77%73\" id=\"nil\"><img border=\"0\" hspace=\"2\" src=\"grayarrow.gif\" vspace=\"3\"/></a><span id=\"down_25496\"></span></center></td><td class=\"title\"><a href=\"https://medium.com/acing-ai/tesla-the-amazon-and-apple-of-the-self-driving-future-ad37e12922f3\" rel=\"nofollow\">Tesla — The Amazon and Apple of the Self Driving Future</a><span class=\"comhead\"> (medium.com) </span></td></tr>\n",
      "<tr><td align=\"right\" class=\"title\" valign=\"top\">10.</td><td><center><a href=\"vote?for=25455&amp;dir=up&amp;whence=%6e%65%77%73\" id=\"nil\"><img border=\"0\" hspace=\"2\" src=\"grayarrow.gif\" vspace=\"3\"/></a><span id=\"down_25455\"></span></center></td><td class=\"title\"><a href=\"http://byteacademy.co/blog/k-means-clustering/\" rel=\"nofollow\">A great guide to K-Means Clustering - Machine Learning</a><span class=\"comhead\"> (byteacademy.co) </span></td></tr>\n",
      "<tr><td align=\"right\" class=\"title\" valign=\"top\">11.</td><td><center><a href=\"vote?for=25472&amp;dir=up&amp;whence=%6e%65%77%73\" id=\"nil\"><img border=\"0\" hspace=\"2\" src=\"grayarrow.gif\" vspace=\"3\"/></a><span id=\"down_25472\"></span></center></td><td class=\"title\"><a href=\"http://rohtas.space/2018-05-25-hackers-guide-to-healthcare-data\" rel=\"nofollow\">Hackers Guide to Healthcare Data</a><span class=\"comhead\"> (rohtas.space) </span></td></tr>\n",
      "<tr><td align=\"right\" class=\"title\" valign=\"top\">12.</td><td><center><a href=\"vote?for=25543&amp;dir=up&amp;whence=%6e%65%77%73\" id=\"nil\"><img border=\"0\" hspace=\"2\" src=\"grayarrow.gif\" vspace=\"3\"/></a><span id=\"down_25543\"></span></center></td><td class=\"title\"><a href=\"https://tech-trending.com/top-8-sites-to-make-money-by-uploading-files/\" rel=\"nofollow\">Top 8 Sites To Make Money By Uploading Files</a><span class=\"comhead\"> (tech-trending.com) </span></td></tr>\n",
      "<tr><td align=\"right\" class=\"title\" valign=\"top\">13.</td><td><center><a href=\"vote?for=25368&amp;dir=up&amp;whence=%6e%65%77%73\" id=\"nil\"><img border=\"0\" hspace=\"2\" src=\"grayarrow.gif\" vspace=\"3\"/></a><span id=\"down_25368\"></span></center></td><td class=\"title\"><a href=\"https://boostlog.io/@nixus89896/17-best-python-libraries-5ad83a3247018500491f3e5b\">17 best python libraries</a><span class=\"comhead\"> (boostlog.io) </span></td></tr>\n",
      "<tr><td align=\"right\" class=\"title\" valign=\"top\">14.</td><td><center><a href=\"vote?for=25186&amp;dir=up&amp;whence=%6e%65%77%73\" id=\"nil\"><img border=\"0\" hspace=\"2\" src=\"grayarrow.gif\" vspace=\"3\"/></a><span id=\"down_25186\"></span></center></td><td class=\"title\"><a href=\"https://medium.com/activewizards-machine-learning-company/top-20-python-libraries-for-data-science-in-2018-2ae7d1db8049\">Top 20 Python libraries for data science in 2018</a><span class=\"comhead\"> (medium.com) </span></td></tr>\n",
      "<tr><td align=\"right\" class=\"title\" valign=\"top\">15.</td><td><center><a href=\"vote?for=25407&amp;dir=up&amp;whence=%6e%65%77%73\" id=\"nil\"><img border=\"0\" hspace=\"2\" src=\"grayarrow.gif\" vspace=\"3\"/></a><span id=\"down_25407\"></span></center></td><td class=\"title\"><a href=\"http://ajknblog.com/basics/hypothesis-testing-prerequisites/\" rel=\"nofollow\">Hypothesis Testing I: Prerequisites</a><span class=\"comhead\"> (ajknblog.com) </span></td></tr>\n",
      "<tr><td align=\"right\" class=\"title\" valign=\"top\">16.</td><td><center><a href=\"vote?for=25434&amp;dir=up&amp;whence=%6e%65%77%73\" id=\"nil\"><img border=\"0\" hspace=\"2\" src=\"grayarrow.gif\" vspace=\"3\"/></a><span id=\"down_25434\"></span></center></td><td class=\"title\"><a href=\"https://www.gethighlights.co/blog/choose-right-analytics-platform/\" rel=\"nofollow\">How to choose the right analytics platform for your team</a><span class=\"comhead\"> (gethighlights.co) </span></td></tr>\n",
      "<tr><td align=\"right\" class=\"title\" valign=\"top\">17.</td><td><center><a href=\"vote?for=25207&amp;dir=up&amp;whence=%6e%65%77%73\" id=\"nil\"><img border=\"0\" hspace=\"2\" src=\"grayarrow.gif\" vspace=\"3\"/></a><span id=\"down_25207\"></span></center></td><td class=\"title\"><a href=\"https://medium.com/activewizards-machine-learning-company/comparison-of-top-data-science-libraries-for-python-r-and-scala-infographic-574069949267\">Comparison of top data science libraries for Python, R and Scala [Infographic]</a><span class=\"comhead\"> (medium.com) </span></td></tr>\n",
      "<tr><td align=\"right\" class=\"title\" valign=\"top\">18.</td><td><center><a href=\"vote?for=25357&amp;dir=up&amp;whence=%6e%65%77%73\" id=\"nil\"><img border=\"0\" hspace=\"2\" src=\"grayarrow.gif\" vspace=\"3\"/></a><span id=\"down_25357\"></span></center></td><td class=\"title\"><a href=\"https://blog.insightdatascience.com/gefilter-fish-finding-concise-topics-from-amazons-customer-reviews-dd14d673ed6d\" rel=\"nofollow\">Gefilter Fish: Finding concise topics from Amazon’s customer reviews</a><span class=\"comhead\"> (insightdatascience.com) </span></td></tr>\n",
      "<tr><td align=\"right\" class=\"title\" valign=\"top\">19.</td><td><center><a href=\"vote?for=25187&amp;dir=up&amp;whence=%6e%65%77%73\" id=\"nil\"><img border=\"0\" hspace=\"2\" src=\"grayarrow.gif\" vspace=\"3\"/></a><span id=\"down_25187\"></span></center></td><td class=\"title\"><a href=\"https://medium.com/nanonets/how-i-built-a-self-flying-drone-to-track-people-in-under-50-lines-of-code-7485de7f828e\">How I built a Self Flying Drone to track People in under 50 lines of code</a><span class=\"comhead\"> (medium.com) </span></td></tr>\n",
      "<tr><td align=\"right\" class=\"title\" valign=\"top\">20.</td><td><center><a href=\"vote?for=25346&amp;dir=up&amp;whence=%6e%65%77%73\" id=\"nil\"><img border=\"0\" hspace=\"2\" src=\"grayarrow.gif\" vspace=\"3\"/></a><span id=\"down_25346\"></span></center></td><td class=\"title\"><a href=\"https://statsbot.co/blog/sql-filter-query/\" rel=\"nofollow\">SQL filter query on FIFA player data</a><span class=\"comhead\"> (statsbot.co) </span></td></tr>\n",
      "<tr><td align=\"right\" class=\"title\" valign=\"top\">21.</td><td><center><a href=\"vote?for=25466&amp;dir=up&amp;whence=%6e%65%77%73\" id=\"nil\"><img border=\"0\" hspace=\"2\" src=\"grayarrow.gif\" vspace=\"3\"/></a><span id=\"down_25466\"></span></center></td><td class=\"title\"><a href=\"https://www.circonus.com/2018/07/monitoring-devops-where-are-we-now-infographic/\" rel=\"nofollow\">Monitoring DevOps: Where are we now? [Infographic]</a><span class=\"comhead\"> (circonus.com) </span></td></tr>\n",
      "<tr><td align=\"right\" class=\"title\" valign=\"top\">22.</td><td><center><a href=\"vote?for=25203&amp;dir=up&amp;whence=%6e%65%77%73\" id=\"nil\"><img border=\"0\" hspace=\"2\" src=\"grayarrow.gif\" vspace=\"3\"/></a><span id=\"down_25203\"></span></center></td><td class=\"title\"><a href=\"https://boostlog.io/@bily809/50-most-popular-python-projects-in-2018-5aea8e1c47018500491f4361\">50 Most Popular Python Projects in 2018</a><span class=\"comhead\"> (boostlog.io) </span></td></tr>\n",
      "<tr><td align=\"right\" class=\"title\" valign=\"top\">23.</td><td><center><a href=\"vote?for=25311&amp;dir=up&amp;whence=%6e%65%77%73\" id=\"nil\"><img border=\"0\" hspace=\"2\" src=\"grayarrow.gif\" vspace=\"3\"/></a><span id=\"down_25311\"></span></center></td><td class=\"title\"><a href=\"https://medium.com/acing-ai/twitter-data-science-interview-questions-acing-the-ai-interview-f8204a97159f\" rel=\"nofollow\">Twitter Data Science Interview Questions - Acing the AI Interview</a><span class=\"comhead\"> (medium.com) </span></td></tr>\n",
      "<tr><td align=\"right\" class=\"title\" valign=\"top\">24.</td><td><center><a href=\"vote?for=25242&amp;dir=up&amp;whence=%6e%65%77%73\" id=\"nil\"><img border=\"0\" hspace=\"2\" src=\"grayarrow.gif\" vspace=\"3\"/></a><span id=\"down_25242\"></span></center></td><td class=\"title\"><a href=\"https://blog.insightdatascience.com/the-unreasonable-effectiveness-of-deep-learning-representations-4ce83fc663cf\">The unreasonable effectiveness of Deep Learning Representations</a><span class=\"comhead\"> (insightdatascience.com) </span></td></tr>\n",
      "<tr><td align=\"right\" class=\"title\" valign=\"top\">25.</td><td><center><a href=\"vote?for=25331&amp;dir=up&amp;whence=%6e%65%77%73\" id=\"nil\"><img border=\"0\" hspace=\"2\" src=\"grayarrow.gif\" vspace=\"3\"/></a><span id=\"down_25331\"></span></center></td><td class=\"title\"><a href=\"https://www.circonus.com/2018/07/a-guide-to-service-level-objectives/\" rel=\"nofollow\">SLO’s &amp; You: A Guide To Service Level Objectives</a><span class=\"comhead\"> (circonus.com) </span></td></tr>\n",
      "<tr><td align=\"right\" class=\"title\" valign=\"top\">26.</td><td><center><a href=\"vote?for=25308&amp;dir=up&amp;whence=%6e%65%77%73\" id=\"nil\"><img border=\"0\" hspace=\"2\" src=\"grayarrow.gif\" vspace=\"3\"/></a><span id=\"down_25308\"></span></center></td><td class=\"title\"><a href=\"https://blog.insightdatascience.com/elastik-nearest-neighbors-4b1f6821bd62\" rel=\"nofollow\">ElastiK Nearest Neighbors: LSH and Elasticsearch for Scalable Online KNN Search</a><span class=\"comhead\"> (insightdatascience.com) </span></td></tr>\n",
      "<tr><td align=\"right\" class=\"title\" valign=\"top\">27.</td><td><center><a href=\"vote?for=25182&amp;dir=up&amp;whence=%6e%65%77%73\" id=\"nil\"><img border=\"0\" hspace=\"2\" src=\"grayarrow.gif\" vspace=\"3\"/></a><span id=\"down_25182\"></span></center></td><td class=\"title\"><a href=\"https://blog.insightdatascience.com/how-to-use-machine-learning-and-quilt-to-identify-buildings-in-satellite-images-aee4e08ab0f3\">How to use Machine Learning and Quilt to Identify Buildings in Satellite Images</a><span class=\"comhead\"> (insightdatascience.com) </span></td></tr>\n",
      "<tr><td align=\"right\" class=\"title\" valign=\"top\">28.</td><td><center><a href=\"vote?for=25168&amp;dir=up&amp;whence=%6e%65%77%73\" id=\"nil\"><img border=\"0\" hspace=\"2\" src=\"grayarrow.gif\" vspace=\"3\"/></a><span id=\"down_25168\"></span></center></td><td class=\"title\"><a href=\"http://tech.marksblogg.com/billion-nyc-taxi-rides-sqlite-parquet-hdfs.html\">1.1 Billion Taxi Rides with SQLite, Parquet &amp; HDFS</a><span class=\"comhead\"> (marksblogg.com) </span></td></tr>\n",
      "<tr><td align=\"right\" class=\"title\" valign=\"top\">29.</td><td><center><a href=\"vote?for=25264&amp;dir=up&amp;whence=%6e%65%77%73\" id=\"nil\"><img border=\"0\" hspace=\"2\" src=\"grayarrow.gif\" vspace=\"3\"/></a><span id=\"down_25264\"></span></center></td><td class=\"title\"><a href=\"https://medium.com/@sr3440/breakfast-with-ai-71a86537ab19\" rel=\"nofollow\">Breakfast with AI</a><span class=\"comhead\"> (medium.com) </span></td></tr>\n",
      "<tr><td align=\"right\" class=\"title\" valign=\"top\">30.</td><td><center><a href=\"vote?for=25223&amp;dir=up&amp;whence=%6e%65%77%73\" id=\"nil\"><img border=\"0\" hspace=\"2\" src=\"grayarrow.gif\" vspace=\"3\"/></a><span id=\"down_25223\"></span></center></td><td class=\"title\"><a href=\"https://dev.to/kazup/sustainable-open-source-ecosystem-with-issuehunt-3h74\" rel=\"nofollow\">Sustainable Open Source Ecosystem with IssueHunt </a><span class=\"comhead\"> (dev.to) </span></td></tr>\n"
     ]
    }
   ],
   "source": [
    "for ix in range(0,90,3):\n",
    "    print rows[ix]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
